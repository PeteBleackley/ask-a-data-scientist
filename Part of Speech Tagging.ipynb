{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import collections\n",
    "import textblob\n",
    "import nltk\n",
    "import numpy\n",
    "import pandas\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 1: Use an off-the-shelf tagger\n",
    "\n",
    "For this we're going to use the `TextBlob` library, as we did in [The Grammar of Truth and Lies](https://youtu.be/OyA59kIQcAU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Peter Bleackley is a self-employed data scientist and computational linguist. He has undertaken \n",
    "Research and Development projects for clients ranging from startups to multinationals. He will shortly be \n",
    "starting a webinar series entitled \"Ask a Data Scientist\". \"\"\"\n",
    "\n",
    "blob = textblob.blob.TextBlob(text)\n",
    "\n",
    "[sentence.pos_tags for sentence in blob.sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 2: Custom trained Average Perceptron Tagger\n",
    "\n",
    "The default tagger in NLTK is an [Average Perceptron Tagger](https://explosion.ai/blog/part-of-speech-pos-tagger-in-python) trained on the Penn Treebank. However, suppose we want to train our model for a different set of tags, such as WordNet word classes. We can do this by using a training corpus derived from Semcor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordNetTaggedCorpus(object):\n",
    "    def __init__(self):\n",
    "        self.fileids = []\n",
    "        path = nltk.find('corpora/semcor')\n",
    "        for directory in ('brown1','brown2'):\n",
    "            self.fileids.extend(['/'.join((directory,'tagfiles',filename))\n",
    "            for filename in os.listdir('{0}/{1}/tagfiles'.format(path,directory))])\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for sentence in tqdm.tqdm(nltk.corpus.semcor.tagged_sents(self.fileids,tag='sem')):\n",
    "            tagged_words = []\n",
    "            for tree in sentence:\n",
    "                if hasattr(tree,'label'):\n",
    "                    if hasattr(tree[0],'label'):\n",
    "                        pos = 'NE' if tree[0].label()=='NE' else tree[0].label().synset().pos()\n",
    "                        tagged_words.extend([(word,pos)\n",
    "                                            for word in tree[0]])\n",
    "                    else:\n",
    "                        label=tree.label()\n",
    "                        pos = label.synset().pos() if hasattr(label,'synset') else label.split('.')[-2] if '.' in label else label\n",
    "                        tagged_words.extend([(word,pos)\n",
    "                                            for word in tree])\n",
    "                else:\n",
    "                    tagged_words.extend([(word,'X') for word in tree])\n",
    "            yield tagged_words\n",
    "                            \n",
    "                                \n",
    "semcor = WordNetTaggedCorpus()\n",
    "                            \n",
    "                                \n",
    "semcor = WordNetTaggedCorpus()\n",
    "tagger = nltk.tag.perceptron.PerceptronTagger(load=False)\n",
    "tagger.train(semcor)\n",
    "[tagger.tag(sentence.words) for sentence in blob.sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 3: Hidden Markov Models\n",
    "\n",
    "For some applications, we may want a probability distribution over the parts of speech, rather than a hard decision. For this, Hidden Markov Models are suitable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMMTagger(object):\n",
    "    \n",
    "    def __init__(self,corpus):\n",
    "        states = ['n','v','a','s','r','NE','X']\n",
    "        n=len(states)\n",
    "        self.initial_state=pandas.Series(numpy.ones(n),\n",
    "                                         index=states)\n",
    "        self.transition_matrix=pandas.DataFrame(numpy.ones((n,n)),\n",
    "                                                index=states,\n",
    "                                                columns=states)\n",
    "        conditional_probs={state:collections.defaultdict(lambda:1.0)\n",
    "                          for state in states}\n",
    "        for sentence in corpus:\n",
    "            prev=None\n",
    "            for (word,pos) in sentence:\n",
    "\n",
    "                if prev is None:\n",
    "                    self.initial_state[pos]+=1.0\n",
    "                else:\n",
    "                    self.transition_matrix.loc[pos,prev]+=1.0\n",
    "                conditional_probs[pos][word]+=1.0\n",
    "                prev=pos\n",
    "        self.initial_state/=self.initial_state.sum()\n",
    "        self.transition_matrix=self.transition_matrix.div(self.transition_matrix.sum(axis=0),\n",
    "                                                          axis='columns')\n",
    "        for state in states:\n",
    "            conditional_probs[state]['OOV']\n",
    "        pOH=pandas.DataFrame(conditional_probs).fillna(1.0)\n",
    "        self.pOH=pOH.div(pOH.sum(axis=0),\n",
    "                         axis='columns')\n",
    "        \n",
    "    def __call__(self,sentence):\n",
    "        result=[]\n",
    "        current = self.initial_state.copy()\n",
    "        for word in sentence:\n",
    "            current*=self.pOH.loc[word if word in self.pOH.index else 'OOV']\n",
    "            current/=current.sum()\n",
    "            result.append(current)\n",
    "            current=self.transition_matrix.dot(current)\n",
    "        return pandas.DataFrame(result)\n",
    "    \n",
    "hmm = HMMTagger(semcor)\n",
    "prob_tags = [hmm(sentence.words)\n",
    "             for sentence in blob.sentences]\n",
    "prob_tags[0].plot.barh(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
